{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7498773,"sourceType":"datasetVersion","datasetId":4366560},{"sourceId":7508525,"sourceType":"datasetVersion","datasetId":4372974},{"sourceId":7523747,"sourceType":"datasetVersion","datasetId":4382661},{"sourceId":7528402,"sourceType":"datasetVersion","datasetId":4384936},{"sourceId":7531185,"sourceType":"datasetVersion","datasetId":4386420},{"sourceId":7531276,"sourceType":"datasetVersion","datasetId":4386472},{"sourceId":7532000,"sourceType":"datasetVersion","datasetId":4386883},{"sourceId":7547645,"sourceType":"datasetVersion","datasetId":4395758},{"sourceId":7561274,"sourceType":"datasetVersion","datasetId":4402810},{"sourceId":7589649,"sourceType":"datasetVersion","datasetId":4417842},{"sourceId":7590933,"sourceType":"datasetVersion","datasetId":4418716},{"sourceId":7590961,"sourceType":"datasetVersion","datasetId":4418735}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import RobertaTokenizer, RobertaModel\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport logging\nfrom tqdm import tqdm\nimport numpy as np\nimport pandas as pd\nfrom sklearn import metrics\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split\n\nlogging.basicConfig(level=logging.ERROR)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T04:27:38.156198Z","iopub.execute_input":"2024-02-09T04:27:38.156540Z","iopub.status.idle":"2024-02-09T04:27:45.988737Z","shell.execute_reply.started":"2024-02-09T04:27:38.156515Z","shell.execute_reply":"2024-02-09T04:27:45.987887Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T04:27:45.990283Z","iopub.execute_input":"2024-02-09T04:27:45.990774Z","iopub.status.idle":"2024-02-09T04:27:46.017546Z","shell.execute_reply.started":"2024-02-09T04:27:45.990746Z","shell.execute_reply":"2024-02-09T04:27:46.016435Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data1= pd.read_csv('/kaggle/input/train-dataaa/train.csv')\ndata2= pd.read_csv('/kaggle/input/dataset1/Distill_Try.csv')","metadata":{"execution":{"iopub.status.busy":"2024-02-09T04:27:46.020021Z","iopub.execute_input":"2024-02-09T04:27:46.020353Z","iopub.status.idle":"2024-02-09T04:27:48.823956Z","shell.execute_reply.started":"2024-02-09T04:27:46.020326Z","shell.execute_reply":"2024-02-09T04:27:48.822951Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data1.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-09T04:27:48.825919Z","iopub.execute_input":"2024-02-09T04:27:48.826224Z","iopub.status.idle":"2024-02-09T04:27:48.843539Z","shell.execute_reply.started":"2024-02-09T04:27:48.826199Z","shell.execute_reply":"2024-02-09T04:27:48.842815Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"      Id                                              Title  \\\n0   9707             Axiomatic Aspects of Default Inference   \n1  24198  On extensions of group with infinite conjugacy...   \n2  35766  An Analysis of Complex-Valued CNNs for RF Data...   \n3  14322  On the reconstruction of the drift of a diffus...   \n4    709  Three classes of propagation rules for GRS and...   \n\n                                            Abstract  \\\n0  This paper studies axioms for nonmonotonic con...   \n1  We characterize the group property of being wi...   \n2  Recent deep neural network-based device classi...   \n3  The problem of reconstructing the drift of a d...   \n4  In this paper, we study the Hermitian hulls of...   \n\n                                 Categories  \n0                                 ['cs.LO']  \n1                               ['math.GR']  \n2  ['cs.LG', 'cs.IT', 'eess.SP', 'math.IT']  \n3         ['math.PR', 'math.ST', 'stat.TH']  \n4                      ['cs.IT', 'math.IT']  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Title</th>\n      <th>Abstract</th>\n      <th>Categories</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9707</td>\n      <td>Axiomatic Aspects of Default Inference</td>\n      <td>This paper studies axioms for nonmonotonic con...</td>\n      <td>['cs.LO']</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>24198</td>\n      <td>On extensions of group with infinite conjugacy...</td>\n      <td>We characterize the group property of being wi...</td>\n      <td>['math.GR']</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>35766</td>\n      <td>An Analysis of Complex-Valued CNNs for RF Data...</td>\n      <td>Recent deep neural network-based device classi...</td>\n      <td>['cs.LG', 'cs.IT', 'eess.SP', 'math.IT']</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14322</td>\n      <td>On the reconstruction of the drift of a diffus...</td>\n      <td>The problem of reconstructing the drift of a d...</td>\n      <td>['math.PR', 'math.ST', 'stat.TH']</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>709</td>\n      <td>Three classes of propagation rules for GRS and...</td>\n      <td>In this paper, we study the Hermitian hulls of...</td>\n      <td>['cs.IT', 'math.IT']</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data2.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-09T04:27:48.844812Z","iopub.execute_input":"2024-02-09T04:27:48.845173Z","iopub.status.idle":"2024-02-09T04:27:48.855956Z","shell.execute_reply.started":"2024-02-09T04:27:48.845141Z","shell.execute_reply":"2024-02-09T04:27:48.854972Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"      Id                                               Text  \\\n0   9707  axiomatic aspects default inference \\n axioms ...   \n1  24198  extensions group infinite conjugacy classes, i...   \n2  35766  analysis complex-valued cnns rf data-driven wi...   \n3  14322  reconstruction drift diffusion from transition...   \n4    709  three classes propagation rules grs egrs codes...   \n\n                                        Tag  \\\n0                                 ['cs.LO']   \n1                               ['math.GR']   \n2  ['cs.LG', 'cs.IT', 'eess.SP', 'math.IT']   \n3         ['math.PR', 'math.ST', 'stat.TH']   \n4                      ['cs.IT', 'math.IT']   \n\n                                                Tags  \n0  [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0...  \n1  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...  \n2  [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0...  \n3  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...  \n4  [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Text</th>\n      <th>Tag</th>\n      <th>Tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9707</td>\n      <td>axiomatic aspects default inference \\n axioms ...</td>\n      <td>['cs.LO']</td>\n      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>24198</td>\n      <td>extensions group infinite conjugacy classes, i...</td>\n      <td>['math.GR']</td>\n      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>35766</td>\n      <td>analysis complex-valued cnns rf data-driven wi...</td>\n      <td>['cs.LG', 'cs.IT', 'eess.SP', 'math.IT']</td>\n      <td>[0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14322</td>\n      <td>reconstruction drift diffusion from transition...</td>\n      <td>['math.PR', 'math.ST', 'stat.TH']</td>\n      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>709</td>\n      <td>three classes propagation rules grs egrs codes...</td>\n      <td>['cs.IT', 'math.IT']</td>\n      <td>[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data = pd.DataFrame()\ndata['text'] = data1['Title'] + \". \" + data1['Abstract']\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T04:27:56.188898Z","iopub.execute_input":"2024-02-09T04:27:56.189533Z","iopub.status.idle":"2024-02-09T04:27:56.265433Z","shell.execute_reply.started":"2024-02-09T04:27:56.189503Z","shell.execute_reply":"2024-02-09T04:27:56.264459Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data['text'] = data['text'].apply(lambda x: x.lower() if isinstance(x, str) else x)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T04:30:34.332998Z","iopub.execute_input":"2024-02-09T04:30:34.333730Z","iopub.status.idle":"2024-02-09T04:30:34.425963Z","shell.execute_reply.started":"2024-02-09T04:30:34.333695Z","shell.execute_reply":"2024-02-09T04:30:34.425080Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"data['labels'] = data2['Tags']","metadata":{"execution":{"iopub.status.busy":"2024-02-09T04:32:17.991902Z","iopub.execute_input":"2024-02-09T04:32:17.992265Z","iopub.status.idle":"2024-02-09T04:32:18.000173Z","shell.execute_reply.started":"2024-02-09T04:32:17.992236Z","shell.execute_reply":"2024-02-09T04:32:17.999327Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import ast","metadata":{"execution":{"iopub.status.busy":"2024-02-09T04:44:22.112706Z","iopub.execute_input":"2024-02-09T04:44:22.113356Z","iopub.status.idle":"2024-02-09T04:44:22.117208Z","shell.execute_reply.started":"2024-02-09T04:44:22.113324Z","shell.execute_reply":"2024-02-09T04:44:22.116204Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def string_to_array(label_string):\n    cleaned_string = label_string.strip('[]').split()\n    return np.array([int(num) for num in cleaned_string])","metadata":{"execution":{"iopub.status.busy":"2024-02-09T04:52:40.984923Z","iopub.execute_input":"2024-02-09T04:52:40.985627Z","iopub.status.idle":"2024-02-09T04:52:40.993149Z","shell.execute_reply.started":"2024-02-09T04:52:40.985593Z","shell.execute_reply":"2024-02-09T04:52:40.992166Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"data['labels'] = data['labels'].apply(string_to_array)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T04:52:45.981739Z","iopub.execute_input":"2024-02-09T04:52:45.982088Z","iopub.status.idle":"2024-02-09T04:52:46.825813Z","shell.execute_reply.started":"2024-02-09T04:52:45.982063Z","shell.execute_reply":"2024-02-09T04:52:46.824989Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"type(data['labels'][0])","metadata":{"execution":{"iopub.status.busy":"2024-02-09T04:52:49.658698Z","iopub.execute_input":"2024-02-09T04:52:49.659519Z","iopub.status.idle":"2024-02-09T04:52:49.665402Z","shell.execute_reply.started":"2024-02-09T04:52:49.659492Z","shell.execute_reply":"2024-02-09T04:52:49.664437Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"numpy.ndarray"},"metadata":{}}]},{"cell_type":"code","source":"# Your data preprocessing steps...\n\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base', truncation=True, do_lower_case=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T04:52:54.766132Z","iopub.execute_input":"2024-02-09T04:52:54.766754Z","iopub.status.idle":"2024-02-09T04:52:55.125414Z","shell.execute_reply.started":"2024-02-09T04:52:54.766722Z","shell.execute_reply":"2024-02-09T04:52:55.124315Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"class MultiLabelDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len):\n        self.tokenizer = tokenizer\n        self.data = dataframe\n        self.text = dataframe.text\n        self.targets = self.data.labels\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self, index):\n        text = self.text[index]\n        text = \" \".join(text.split())\n\n        inputs = self.tokenizer.encode_plus(\n            text,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            pad_to_max_length=True,\n            return_token_type_ids=True,\n            return_tensors='pt'\n        )\n        ids = inputs['input_ids'].squeeze()\n        mask = inputs['attention_mask'].squeeze()\n        token_type_ids = inputs[\"token_type_ids\"].squeeze()\n\n        return {\n            'ids': ids,\n            'mask': mask,\n            'token_type_ids': token_type_ids,\n            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n        }\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T04:52:56.263340Z","iopub.execute_input":"2024-02-09T04:52:56.264311Z","iopub.status.idle":"2024-02-09T04:52:56.275542Z","shell.execute_reply.started":"2024-02-09T04:52:56.264275Z","shell.execute_reply":"2024-02-09T04:52:56.274382Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# Splitting data into train and test\ntrain_size = 0.8\ntrain_data, test_data = train_test_split(data, test_size=1-train_size, random_state=200)\ntrain_data = train_data.reset_index(drop=True)\ntest_data = test_data.reset_index(drop=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T04:52:57.831015Z","iopub.execute_input":"2024-02-09T04:52:57.831642Z","iopub.status.idle":"2024-02-09T04:52:57.857433Z","shell.execute_reply.started":"2024-02-09T04:52:57.831612Z","shell.execute_reply":"2024-02-09T04:52:57.856537Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2024-02-09T04:52:59.368719Z","iopub.execute_input":"2024-02-09T04:52:59.369104Z","iopub.status.idle":"2024-02-09T04:52:59.388688Z","shell.execute_reply.started":"2024-02-09T04:52:59.369073Z","shell.execute_reply":"2024-02-09T04:52:59.387691Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"                                                    text  \\\n0      deployable reinforcement learning with variabl...   \n1      biphasic face photo-sketch synthesis via seman...   \n2      sequential information guided sensing. we stud...   \n3      feature hashing for large scale multitask lear...   \n4      a schlichtness theorem for envelopes of holomo...   \n...                                                  ...   \n40963  orthogonal layers of parallelism in large-scal...   \n40964  private set intersection: a multi-message symm...   \n40965  compilation of hpsg to tag. we present an impl...   \n40966  global well-posedness for kdv in sobolev space...   \n40967  petascale computational systems. computational...   \n\n                                                  labels  \n0      [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n1      [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n2      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n3      [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n...                                                  ...  \n40963  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n40964  [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n40965  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n40966  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n40967  [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n\n[40968 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>deployable reinforcement learning with variabl...</td>\n      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>biphasic face photo-sketch synthesis via seman...</td>\n      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sequential information guided sensing. we stud...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>feature hashing for large scale multitask lear...</td>\n      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a schlichtness theorem for envelopes of holomo...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>40963</th>\n      <td>orthogonal layers of parallelism in large-scal...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>40964</th>\n      <td>private set intersection: a multi-message symm...</td>\n      <td>[0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>40965</th>\n      <td>compilation of hpsg to tag. we present an impl...</td>\n      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>40966</th>\n      <td>global well-posedness for kdv in sobolev space...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>40967</th>\n      <td>petascale computational systems. computational...</td>\n      <td>[0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>40968 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"MAX_LEN = 350\nTRAIN_BATCH_SIZE = 32\nVALID_BATCH_SIZE = 32\nEPOCHS = 25\nLEARNING_RATE = 1e-05\n\ntraining_set = MultiLabelDataset(train_data, tokenizer, MAX_LEN)\ntesting_set = MultiLabelDataset(test_data, tokenizer, MAX_LEN)\n\ntrain_params = {'batch_size': TRAIN_BATCH_SIZE,\n                'shuffle': True,\n                'num_workers': 0\n                }\n\ntest_params = {'batch_size': VALID_BATCH_SIZE,\n                'shuffle': True,\n                'num_workers': 0\n                }\n\ntraining_loader = DataLoader(training_set, **train_params)\ntesting_loader = DataLoader(testing_set, **test_params)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T04:53:01.205590Z","iopub.execute_input":"2024-02-09T04:53:01.206550Z","iopub.status.idle":"2024-02-09T04:53:01.213368Z","shell.execute_reply.started":"2024-02-09T04:53:01.206516Z","shell.execute_reply":"2024-02-09T04:53:01.212428Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"testing_loader","metadata":{"execution":{"iopub.status.busy":"2024-02-09T04:53:03.639244Z","iopub.execute_input":"2024-02-09T04:53:03.639611Z","iopub.status.idle":"2024-02-09T04:53:03.645655Z","shell.execute_reply.started":"2024-02-09T04:53:03.639582Z","shell.execute_reply":"2024-02-09T04:53:03.644735Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"<torch.utils.data.dataloader.DataLoader at 0x7fe72f1bfbb0>"},"metadata":{}}]},{"cell_type":"code","source":"class RoBERTaClass(torch.nn.Module):\n    def __init__(self):\n        super(RoBERTaClass, self).__init__()\n        self.l1 = RobertaModel.from_pretrained(\"roberta-base\")\n        self.linear1 = torch.nn.Linear(768, 512)\n        self.dropout = torch.nn.Dropout(0.1)\n        self.linear2 = torch.nn.Linear(512, 256)\n        self.leaky_relu = torch.nn.LeakyReLU()\n        self.linear3 = torch.nn.Linear(256, 64)\n        self.tanh = torch.nn.Tanh()\n        self.classifier = torch.nn.Linear(64, 57)\n\n    def forward(self, input_ids, attention_mask, token_type_ids):\n        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n        hidden_state = output_1.last_hidden_state\n        pooler = hidden_state[:, 0]\n\n        linear1_output = self.linear1(pooler)\n        linear1_output = self.dropout(linear1_output)\n\n        linear2_output = self.linear2(linear1_output)\n        linear2_output = self.leaky_relu(linear2_output)\n\n        linear3_output = self.linear3(linear2_output)\n        linear3_output = self.leaky_relu(linear3_output)\n\n        output = self.classifier(linear3_output)\n        return output\n\nmodel = RoBERTaClass()\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T04:53:05.918929Z","iopub.execute_input":"2024-02-09T04:53:05.919619Z","iopub.status.idle":"2024-02-09T04:53:06.550339Z","shell.execute_reply.started":"2024-02-09T04:53:05.919583Z","shell.execute_reply":"2024-02-09T04:53:06.549457Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"RoBERTaClass(\n  (l1): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): RobertaPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (linear1): Linear(in_features=768, out_features=512, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n  (linear2): Linear(in_features=512, out_features=256, bias=True)\n  (leaky_relu): LeakyReLU(negative_slope=0.01)\n  (linear3): Linear(in_features=256, out_features=64, bias=True)\n  (tanh): Tanh()\n  (classifier): Linear(in_features=64, out_features=57, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"\ndef loss_fn(outputs, targets):\n    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n\noptimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T04:53:09.775476Z","iopub.execute_input":"2024-02-09T04:53:09.776313Z","iopub.status.idle":"2024-02-09T04:53:09.782918Z","shell.execute_reply.started":"2024-02-09T04:53:09.776275Z","shell.execute_reply":"2024-02-09T04:53:09.781931Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"def train(epoch):\n    model.train()\n    total_loss = 0\n    \n    for _, data in tqdm(enumerate(training_loader, 0)):\n        ids = data['ids'].to(device, dtype=torch.long)\n        mask = data['mask'].to(device, dtype=torch.long)\n        token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n        targets = data['targets'].to(device, dtype=torch.float)\n\n        outputs = model(ids, mask, token_type_ids)\n        optimizer.zero_grad()\n        loss = loss_fn(outputs, targets)\n        total_loss += loss.item()\n\n        if _ % 500 == 0:\n            print(f'Epoch: {epoch}, Iteration: {_}, Loss: {loss.item()}')\n\n        loss.backward()\n        optimizer.step()\n\n    print(f'Epoch: {epoch}, Average Loss: {total_loss / len(training_loader)}')\n\n    # Save the model after every epoch\n    torch.save(model.state_dict(), f'roberta_model_epoch_{epoch+1}.pt')\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T04:53:10.849285Z","iopub.execute_input":"2024-02-09T04:53:10.849663Z","iopub.status.idle":"2024-02-09T04:53:10.857849Z","shell.execute_reply.started":"2024-02-09T04:53:10.849633Z","shell.execute_reply":"2024-02-09T04:53:10.856842Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# Training loop\nfor epoch in range(EPOCHS):\n    train(epoch)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T04:53:12.151151Z","iopub.execute_input":"2024-02-09T04:53:12.151533Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2619: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 0, Loss: 0.6957668662071228\n","output_type":"stream"},{"name":"stderr","text":"36it [00:38,  1.05s/it]","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}